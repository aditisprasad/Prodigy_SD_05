import requests
from bs4 import BeautifulSoup
import pandas as pd

BASE_URL = 'https://books.toscrape.com/catalogue/page-{}.html'
books = []

for page in range(1, 5 + 1):  # Scrape first 5 pages
    print(f"Scraping page {page}...")
    url = BASE_URL.format(page)
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    articles = soup.find_all('article', class_='product_pod')
    
    for article in articles:
        name = article.h3.a['title']
        price = article.find('p', class_='price_color').text.strip()
        rating_class = article.find('p', class_='star-rating')['class']
        rating = rating_class[1]  # e.g., 'Three', 'Five'

        books.append({
            'Name': name,
            'Price': price,
            'Rating': rating
        })

# Save to CSV
df = pd.DataFrame(books)
df.to_csv('books.csv', index=False)
print("âœ… Data saved successfully to books.csv")
